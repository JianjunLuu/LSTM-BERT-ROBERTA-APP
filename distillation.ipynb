{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c10997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "E:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "E:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ===== 1. 加载BERT教师模型 =====\n",
    "# 设备设置\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# 加载模型和 tokenizer\n",
    "model_path = \"C:/Users/ASUS/BERT/saved_model\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# 将模型移动到设备并设置为评估模式\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21242e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dear principal hearing quite lot subject commu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dear state senator writing express opinion ele...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high school students constantly bombarded info...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi im 6th garden think zoos ane nearly cool iv...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sure jars attempt writing essay average 8tj gr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>good actions helpful ways good altered led goo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>article unmaking face mars explains face mars ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>driving extremely dangerous anyone else especi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>hey know people say kindness goes long way yea...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>dont agree driveless cars lot things go wrong ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                cleaned  label\n",
       "0     dear principal hearing quite lot subject commu...    0.0\n",
       "1     dear state senator writing express opinion ele...    1.0\n",
       "2     high school students constantly bombarded info...    1.0\n",
       "3     hi im 6th garden think zoos ane nearly cool iv...    1.0\n",
       "4     sure jars attempt writing essay average 8tj gr...    1.0\n",
       "...                                                 ...    ...\n",
       "9995  good actions helpful ways good altered led goo...    0.0\n",
       "9996  article unmaking face mars explains face mars ...    0.0\n",
       "9997  driving extremely dangerous anyone else especi...    0.0\n",
       "9998  hey know people say kindness goes long way yea...    1.0\n",
       "9999  dont agree driveless cars lot things go wrong ...    0.0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "# 数据读取\n",
    "\n",
    "data = pd.read_csv('C:/Users/ASUS/BERT/AI_Human.csv')\n",
    "\n",
    "# 数据采样与清洗\n",
    "ai_samples = data[data['generated'] == 1]\n",
    "human_samples = data[data['generated'] == 0]\n",
    "data = pd.concat([ai_samples.sample(n=5000, random_state=42), human_samples.sample(n=5000, random_state=42)])\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 清洗函数\n",
    "def remove_punc(text):\n",
    "    return ''.join([char for char in text if char not in punctuation])\n",
    "\n",
    "def remove_stop(text):\n",
    "    stops = set(stopwords.words('english'))\n",
    "    return \" \".join([word for word in text.split() if word.lower() not in stops])\n",
    "\n",
    "# 文本清洗\n",
    "data['cleaned'] = data['text'].str.lower()\n",
    "data['cleaned'] = data['cleaned'].apply(lambda x: re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', x, flags=re.MULTILINE))\n",
    "data['cleaned'] = data['cleaned'].apply(lambda x: re.sub(r'<.*?>', '', x))\n",
    "data['cleaned'] = data['cleaned'].apply(remove_punc)\n",
    "data['cleaned'] = data['cleaned'].apply(remove_stop)\n",
    "\n",
    "data = data[['cleaned', 'generated']]\n",
    "data.rename(columns={'generated': 'label'}, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d43868e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>here’s reworded passage repetitive phrases pat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>certainly reworded version passage repetitive ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>certainly reworded version passage repetitive ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>here’s reworded passage repetitive phrases pat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>certainly here’s reworded version repetitive p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>curiosity nature humans curiosity gotten us pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>dear principal area decision thinking making c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>every told adults always around teenagers righ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>people complain car arent allowed complete cer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>face mars real fake explanation human like fac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                cleaned  label\n",
       "0     here’s reworded passage repetitive phrases pat...      1\n",
       "1     certainly reworded version passage repetitive ...      1\n",
       "2     certainly reworded version passage repetitive ...      1\n",
       "3     here’s reworded passage repetitive phrases pat...      1\n",
       "4     certainly here’s reworded version repetitive p...      1\n",
       "...                                                 ...    ...\n",
       "3995  curiosity nature humans curiosity gotten us pl...      0\n",
       "3996  dear principal area decision thinking making c...      0\n",
       "3997  every told adults always around teenagers righ...      0\n",
       "3998  people complain car arent allowed complete cer...      0\n",
       "3999  face mars real fake explanation human like fac...      0\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_enhanced = pd.read_csv('C:/Users/ASUS/BERT/data_Enhance/enhanceded_ai_human.csv')\n",
    "# 文本清洗\n",
    "data_enhanced ['cleaned'] = data_enhanced ['text'].str.lower()\n",
    "data_enhanced ['cleaned'] = data_enhanced ['cleaned'].apply(lambda x: re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', x, flags=re.MULTILINE))\n",
    "data_enhanced ['cleaned'] = data_enhanced ['cleaned'].apply(lambda x: re.sub(r'<.*?>', '', x))\n",
    "data_enhanced ['cleaned'] = data_enhanced ['cleaned'].apply(remove_punc)\n",
    "data_enhanced ['cleaned'] = data_enhanced ['cleaned'].apply(remove_stop)\n",
    "\n",
    "data_enhanced  = data_enhanced [['cleaned', 'label']]\n",
    "data_enhanced "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198ef6a2",
   "metadata": {},
   "source": [
    "## 使用BERT为增强数据生成 soft label（logits）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "855c442e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▌                                                                        | 709/10000 [00:15<03:17, 46.97it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "\n",
    "def generate_soft_labels(df, model, tokenizer, device, max_len=256):\n",
    "    distilled_data = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text = row['cleaned']\n",
    "        label = int(row['label'])\n",
    "\n",
    "        # BERT 编码\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_len).to(device)\n",
    "\n",
    "        # 前向传播（不计算梯度）\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits.squeeze().cpu().tolist()\n",
    "\n",
    "        # 保存为 soft label\n",
    "        distilled_data.append({\n",
    "            \"text\": text,\n",
    "            \"label\": label,\n",
    "            \"teacher_logits\": logits\n",
    "        })\n",
    "\n",
    "    return distilled_data\n",
    "\n",
    "# 创建保存目录\n",
    "os.makedirs(\"distilled_data\", exist_ok=True)\n",
    "\n",
    "# 示例：对原始数据进行蒸馏\n",
    "distilled_original = generate_soft_labels(data, model, tokenizer, device)\n",
    "with open(\"distilled_data/distill_original.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(distilled_original, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 示例：对增强数据进行蒸馏\n",
    "distilled_augmented = generate_soft_labels(data_enhanced, model, tokenizer, device)\n",
    "with open(\"distilled_data/distill_augmented.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(distilled_augmented, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d85bb",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e4e9779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class DistilledDataset(Dataset):\n",
    "    def __init__(self, json_file, tokenizer, max_len=256):\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            self.data = json.load(f)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        encoded = self.tokenizer(item['text'], padding='max_length', truncation=True,\n",
    "                                 max_length=self.max_len, return_tensors='pt')\n",
    "        input_ids = encoded['input_ids'].squeeze()\n",
    "        attention_mask = encoded['attention_mask'].squeeze()\n",
    "        soft_labels = torch.tensor(item['teacher_logits'], dtype=torch.float32)\n",
    "        hard_label = torch.tensor(item['label'], dtype=torch.long)\n",
    "        return input_ids, attention_mask, soft_labels, hard_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed98a05",
   "metadata": {},
   "source": [
    "## 定义 LSTM 学生模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7211fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMStudent(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_classes=2):\n",
    "        super(LSTMStudent, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        embeds = self.embedding(input_ids)\n",
    "        _, (hidden, _) = self.lstm(embeds)\n",
    "        logits = self.classifier(hidden[-1])\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e928e",
   "metadata": {},
   "source": [
    "## 训练函数（带蒸馏 loss）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b1b3aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation_loss(student_logits, teacher_logits, true_labels, T=2.0, alpha=0.7):\n",
    "    loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "    ce_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    soft_loss = loss_fn(\n",
    "        nn.functional.log_softmax(student_logits / T, dim=1),\n",
    "        nn.functional.softmax(teacher_logits / T, dim=1)\n",
    "    ) * (T * T)\n",
    "\n",
    "    hard_loss = ce_loss_fn(student_logits, true_labels)\n",
    "\n",
    "    return alpha * soft_loss + (1 - alpha) * hard_loss\n",
    "\n",
    "def train_lstm_model(model, dataloader, optimizer, device, epochs=5):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for input_ids, attention_mask, teacher_logits, labels in dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "            teacher_logits = teacher_logits.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            student_logits = model(input_ids)\n",
    "            loss = distillation_loss(student_logits, teacher_logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc1ab96",
   "metadata": {},
   "source": [
    "## 加载数据并训练两个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3580b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"C:/Users/ASUS/BERT/saved_model\")\n",
    "\n",
    "# 加载数据集\n",
    "dataset_orig = DistilledDataset(\"distilled_data/distill_original.json\", tokenizer)\n",
    "dataset_aug = DistilledDataset(\"distilled_data/distill_augmented.json\", tokenizer)\n",
    "\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# 假设你想用 10% 作为测试集\n",
    "test_ratio = 0.1\n",
    "total_size = len(dataset_orig)\n",
    "test_size = int(total_size * test_ratio)\n",
    "train_size = total_size - test_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset_orig, [train_size, test_size])\n",
    "dataset_orig=train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f10a245d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.7726769734781684\n",
      "Epoch 2, Loss: 1.7275419400093404\n",
      "Epoch 3, Loss: 1.4880417908759827\n",
      "Epoch 4, Loss: 0.9800037436240109\n",
      "Epoch 5, Loss: 1.3112991045341424\n",
      "Epoch 1, Loss: 1.5974644343058269\n",
      "Epoch 2, Loss: 1.0241202890078227\n",
      "Epoch 3, Loss: 1.02368297568957\n",
      "Epoch 4, Loss: 0.7204754469792048\n",
      "Epoch 5, Loss: 0.6120695053736369\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataloader_orig = DataLoader(dataset_orig, batch_size=32, shuffle=True)\n",
    "dataloader_aug = DataLoader(dataset_aug, batch_size=32, shuffle=True)\n",
    "\n",
    "# 词表大小\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "# 初始化两个学生模型\n",
    "lstm_orig = LSTMStudent(vocab_size)\n",
    "lstm_aug = LSTMStudent(vocab_size)\n",
    "\n",
    "# 优化器\n",
    "optimizer_orig = torch.optim.Adam(lstm_orig.parameters(), lr=2e-4)\n",
    "optimizer_aug = torch.optim.Adam(lstm_aug.parameters(), lr=2e-4)\n",
    "\n",
    "# 训练\n",
    "train_lstm_model(lstm_orig, dataloader_orig, optimizer_orig, device)\n",
    "train_lstm_model(lstm_aug, dataloader_aug, optimizer_aug, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92debc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_orig.state_dict(), \"lstm_original.pt\")\n",
    "torch.save(lstm_aug.state_dict(), \"lstm_augmented.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5607a619",
   "metadata": {},
   "source": [
    "## 测试并加权融合两个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4c183a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23044\\492350473.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lstm_orig.load_state_dict(torch.load(\"lstm_original.pt\", map_location=device))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23044\\492350473.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lstm_aug.load_state_dict(torch.load(\"lstm_augmented.pt\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1])\n",
      "Test Accuracy: 0.8890\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ========== 定义模型结构 ==========\n",
    "class LSTMStudent(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_classes=2):\n",
    "        super(LSTMStudent, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        embeds = self.embedding(input_ids)\n",
    "        _, (hidden, _) = self.lstm(embeds)\n",
    "        logits = self.classifier(hidden[-1])\n",
    "        return logits\n",
    "\n",
    "# ========== 模型初始化与加载 ==========\n",
    "vocab_size = 30522  # 与训练时一致\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 初始化模型并加载权重\n",
    "lstm_orig = LSTMStudent(vocab_size).to(device)\n",
    "lstm_aug = LSTMStudent(vocab_size).to(device)\n",
    "\n",
    "lstm_orig.load_state_dict(torch.load(\"lstm_original.pt\", map_location=device))\n",
    "lstm_aug.load_state_dict(torch.load(\"lstm_augmented.pt\", map_location=device))\n",
    "\n",
    "lstm_orig.eval()\n",
    "lstm_aug.eval()\n",
    "\n",
    "# ========== 定义预测函数 ==========\n",
    "def predict_lstm(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, _, _, _ in dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            logits = model(input_ids)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds.append(probs.cpu())\n",
    "    return torch.cat(preds, dim=0)\n",
    "\n",
    "# ========== 执行预测 ==========\n",
    "# 提前准备好 test_dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 预测两个模型输出的概率分布\n",
    "probs_orig = predict_lstm(lstm_orig, test_loader, device)\n",
    "probs_aug = predict_lstm(lstm_aug, test_loader, device)\n",
    "\n",
    "# ========== 加权融合 ==========0.3，0.7\n",
    "final_probs = 0.5* probs_orig + 0.5 * probs_aug\n",
    "final_preds = torch.argmax(final_probs, dim=1)\n",
    "\n",
    "# 输出预测结果\n",
    "print(final_preds)\n",
    "true_labels = torch.tensor([label.item() for _, _, _, label in test_dataset])\n",
    "# 计算准确率\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(true_labels, final_preds)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9144b182",
   "metadata": {},
   "source": [
    "## 攻击\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e08b277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, csv_path, tokenizer, max_length=128):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.data.iloc[idx]['text'])\n",
    "        label = int(self.data.iloc[idx]['label'])\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        return input_ids, 0, 0, torch.tensor(label)\n",
    "test_dataset_attack = CSVDataset(\"C:/Users/ASUS/BERT/attack/ai_rewritten_in_human_style.csv\", tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "509ea2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23044\\2823846473.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lstm_orig.load_state_dict(torch.load(\"lstm_original.pt\", map_location=device))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_23044\\2823846473.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lstm_aug.load_state_dict(torch.load(\"lstm_augmented.pt\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1,  ..., 1, 1, 1])\n",
      "Test Accuracy: 0.9740\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ========== 定义模型结构 ==========\n",
    "class LSTMStudent(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_classes=2):\n",
    "        super(LSTMStudent, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        embeds = self.embedding(input_ids)\n",
    "        _, (hidden, _) = self.lstm(embeds)\n",
    "        logits = self.classifier(hidden[-1])\n",
    "        return logits\n",
    "\n",
    "# ========== 模型初始化与加载 ==========\n",
    "vocab_size = 30522  # 与训练时一致\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 初始化模型并加载权重\n",
    "lstm_orig = LSTMStudent(vocab_size).to(device)\n",
    "lstm_aug = LSTMStudent(vocab_size).to(device)\n",
    "\n",
    "lstm_orig.load_state_dict(torch.load(\"lstm_original.pt\", map_location=device))\n",
    "lstm_aug.load_state_dict(torch.load(\"lstm_augmented.pt\", map_location=device))\n",
    "\n",
    "lstm_orig.eval()\n",
    "lstm_aug.eval()\n",
    "\n",
    "# ========== 定义预测函数 ==========\n",
    "def predict_lstm(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, _, _, _ in dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            logits = model(input_ids)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds.append(probs.cpu())\n",
    "    return torch.cat(preds, dim=0)\n",
    "\n",
    "# ========== 执行预测 ==========\n",
    "# 提前准备好 test_dataset\n",
    "test_loader = DataLoader(test_dataset_attack, batch_size=32, shuffle=False)\n",
    "\n",
    "# 预测两个模型输出的概率分布\n",
    "probs_orig = predict_lstm(lstm_orig, test_loader, device)\n",
    "probs_aug = predict_lstm(lstm_aug, test_loader, device)\n",
    "\n",
    "# ========== 加权融合 ==========0.3，0.7\n",
    "final_probs = 0.5* probs_orig + 0.5 * probs_aug\n",
    "final_preds = torch.argmax(final_probs, dim=1)\n",
    "\n",
    "# 输出预测结果\n",
    "print(final_preds)\n",
    "true_labels = torch.tensor([label.item() for _, _, _, label in test_dataset_attack])\n",
    "# 计算准确率\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(true_labels, final_preds)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad854578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
