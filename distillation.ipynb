{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75c10997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "E:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "E:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "E:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ===== 1. 加载BERT教师模型 =====\n",
    "# 设备设置\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# 加载模型和 tokenizer\n",
    "model_path = \"C:/Users/ASUS/BERT/saved_model\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# 将模型移动到设备并设置为评估模式\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21242e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dear principal hearing quite lot subject commu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dear state senator writing express opinion ele...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high school students constantly bombarded info...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi im 6th garden think zoos ane nearly cool iv...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sure jars attempt writing essay average 8tj gr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>good actions helpful ways good altered led goo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>article unmaking face mars explains face mars ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>driving extremely dangerous anyone else especi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>hey know people say kindness goes long way yea...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>dont agree driveless cars lot things go wrong ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                cleaned  label\n",
       "0     dear principal hearing quite lot subject commu...    0.0\n",
       "1     dear state senator writing express opinion ele...    1.0\n",
       "2     high school students constantly bombarded info...    1.0\n",
       "3     hi im 6th garden think zoos ane nearly cool iv...    1.0\n",
       "4     sure jars attempt writing essay average 8tj gr...    1.0\n",
       "...                                                 ...    ...\n",
       "9995  good actions helpful ways good altered led goo...    0.0\n",
       "9996  article unmaking face mars explains face mars ...    0.0\n",
       "9997  driving extremely dangerous anyone else especi...    0.0\n",
       "9998  hey know people say kindness goes long way yea...    1.0\n",
       "9999  dont agree driveless cars lot things go wrong ...    0.0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "# 数据读取\n",
    "data = pd.read_csv('C:/Users/ASUS/BERT/AI_Human.csv')\n",
    "\n",
    "# 数据采样与清洗\n",
    "ai_samples = data[data['generated'] == 1]\n",
    "human_samples = data[data['generated'] == 0]\n",
    "data = pd.concat([ai_samples.sample(n=5000, random_state=42), human_samples.sample(n=5000, random_state=42)])\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 清洗函数\n",
    "def remove_punc(text):\n",
    "    return ''.join([char for char in text if char not in punctuation])\n",
    "\n",
    "def remove_stop(text):\n",
    "    stops = set(stopwords.words('english'))\n",
    "    return \" \".join([word for word in text.split() if word.lower() not in stops])\n",
    "\n",
    "# 文本清洗\n",
    "data['cleaned'] = data['text'].str.lower()\n",
    "data['cleaned'] = data['cleaned'].apply(lambda x: re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', x, flags=re.MULTILINE))\n",
    "data['cleaned'] = data['cleaned'].apply(lambda x: re.sub(r'<.*?>', '', x))\n",
    "data['cleaned'] = data['cleaned'].apply(remove_punc)\n",
    "data['cleaned'] = data['cleaned'].apply(remove_stop)\n",
    "\n",
    "data = data[['cleaned', 'generated']]\n",
    "data.rename(columns={'generated': 'label'}, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d43868e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>famous quote thomas jefferson advised us deter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nowadays people make advertisements sh fed sh ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cell phones love em hate em theyre stay using ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development countrys economic travelling becom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ip todays fast paced world becoming increasing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>deal principal personally dont mind community ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>seagoing cowboy program hard work pretty fun g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>years 1976 spacecraft snapped photographs poss...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>may think landform resembles human face proof ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>drivers able phone driving opinion question wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 cleaned  label\n",
       "0      famous quote thomas jefferson advised us deter...      1\n",
       "1      nowadays people make advertisements sh fed sh ...      1\n",
       "2      cell phones love em hate em theyre stay using ...      1\n",
       "3      development countrys economic travelling becom...      1\n",
       "4      ip todays fast paced world becoming increasing...      1\n",
       "...                                                  ...    ...\n",
       "11995  deal principal personally dont mind community ...      0\n",
       "11996  seagoing cowboy program hard work pretty fun g...      0\n",
       "11997  years 1976 spacecraft snapped photographs poss...      0\n",
       "11998  may think landform resembles human face proof ...      0\n",
       "11999  drivers able phone driving opinion question wo...      0\n",
       "\n",
       "[12000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_enhanced = pd.read_csv('C:/Users/ASUS/BERT/data_Enhance/enhanceded_ai_human.csv')\n",
    "# 文本清洗\n",
    "data_enhanced ['cleaned'] = data_enhanced ['text'].str.lower()\n",
    "data_enhanced ['cleaned'] = data_enhanced ['cleaned'].apply(lambda x: re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', x, flags=re.MULTILINE))\n",
    "data_enhanced ['cleaned'] = data_enhanced ['cleaned'].apply(lambda x: re.sub(r'<.*?>', '', x))\n",
    "data_enhanced ['cleaned'] = data_enhanced ['cleaned'].apply(remove_punc)\n",
    "data_enhanced ['cleaned'] = data_enhanced ['cleaned'].apply(remove_stop)\n",
    "\n",
    "data_enhanced  = data_enhanced [['cleaned', 'label']]\n",
    "data_enhanced "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198ef6a2",
   "metadata": {},
   "source": [
    "## 使用BERT为增强数据生成 soft label（logits）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "855c442e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [03:28<00:00, 47.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 12000/12000 [04:20<00:00, 46.04it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "\n",
    "def generate_soft_labels(df, model, tokenizer, device, max_len=256):\n",
    "    distilled_data = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        text = row['cleaned']\n",
    "        label = int(row['label'])\n",
    "\n",
    "        # BERT 编码\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=max_len).to(device)\n",
    "\n",
    "        # 前向传播（不计算梯度）\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits.squeeze().cpu().tolist()\n",
    "\n",
    "        # 保存为 soft label\n",
    "        distilled_data.append({\n",
    "            \"text\": text,\n",
    "            \"label\": label,\n",
    "            \"teacher_logits\": logits\n",
    "        })\n",
    "\n",
    "    return distilled_data\n",
    "\n",
    "# 创建保存目录\n",
    "os.makedirs(\"distilled_data\", exist_ok=True)\n",
    "\n",
    "# 示例：对原始数据进行蒸馏\n",
    "distilled_original = generate_soft_labels(data, model, tokenizer, device)\n",
    "with open(\"distilled_data/distill_original.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(distilled_original, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 示例：对增强数据进行蒸馏\n",
    "distilled_augmented = generate_soft_labels(data_enhanced, model, tokenizer, device)\n",
    "with open(\"distilled_data/distill_augmented.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(distilled_augmented, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d85bb",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e4e9779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class DistilledDataset(Dataset):\n",
    "    def __init__(self, json_file, tokenizer, max_len=256):\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            self.data = json.load(f)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        encoded = self.tokenizer(item['text'], padding='max_length', truncation=True,\n",
    "                                 max_length=self.max_len, return_tensors='pt')\n",
    "        input_ids = encoded['input_ids'].squeeze()\n",
    "        attention_mask = encoded['attention_mask'].squeeze()\n",
    "        soft_labels = torch.tensor(item['teacher_logits'], dtype=torch.float32)\n",
    "        hard_label = torch.tensor(item['label'], dtype=torch.long)\n",
    "        return input_ids, attention_mask, soft_labels, hard_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed98a05",
   "metadata": {},
   "source": [
    "## 定义 LSTM 学生模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7211fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMStudent(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_classes=2):\n",
    "        super(LSTMStudent, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        embeds = self.embedding(input_ids)\n",
    "        _, (hidden, _) = self.lstm(embeds)\n",
    "        logits = self.classifier(hidden[-1])\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e928e",
   "metadata": {},
   "source": [
    "## 训练函数（带蒸馏 loss）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1b3aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation_loss(student_logits, teacher_logits, true_labels, T=2.0, alpha=0.7):\n",
    "    loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "    ce_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    soft_loss = loss_fn(\n",
    "        nn.functional.log_softmax(student_logits / T, dim=1),\n",
    "        nn.functional.softmax(teacher_logits / T, dim=1)\n",
    "    ) * (T * T)\n",
    "\n",
    "    hard_loss = ce_loss_fn(student_logits, true_labels)\n",
    "\n",
    "    return alpha * soft_loss + (1 - alpha) * hard_loss\n",
    "\n",
    "def train_lstm_model(model, dataloader, optimizer, device, epochs=5):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for input_ids, attention_mask, teacher_logits, labels in dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "            teacher_logits = teacher_logits.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            student_logits = model(input_ids)\n",
    "            loss = distillation_loss(student_logits, teacher_logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc1ab96",
   "metadata": {},
   "source": [
    "## 加载数据并训练两个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3580b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"C:/Users/ASUS/BERT/saved_model\")\n",
    "\n",
    "# 加载数据集\n",
    "dataset_orig = DistilledDataset(\"distilled_data/distill_original.json\", tokenizer)\n",
    "dataset_aug = DistilledDataset(\"distilled_data/distill_augmented.json\", tokenizer)\n",
    "\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# 假设你想用 10% 作为测试集\n",
    "test_ratio = 0.1\n",
    "total_size = len(dataset_orig)\n",
    "test_size = int(total_size * test_ratio)\n",
    "train_size = total_size - test_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset_orig, [train_size, test_size])\n",
    "dataset_orig=train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f10a245d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.7689249722670155\n",
      "Epoch 2, Loss: 1.7010296841039725\n",
      "Epoch 3, Loss: 1.4194721839529403\n",
      "Epoch 4, Loss: 1.6381639189331243\n",
      "Epoch 5, Loss: 1.6817485952208229\n",
      "Epoch 1, Loss: 1.5574285259246827\n",
      "Epoch 2, Loss: 1.0077976038455962\n",
      "Epoch 3, Loss: 0.8074995681444804\n",
      "Epoch 4, Loss: 0.6403694864908854\n",
      "Epoch 5, Loss: 0.584245181719462\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataloader_orig = DataLoader(dataset_orig, batch_size=32, shuffle=True)\n",
    "dataloader_aug = DataLoader(dataset_aug, batch_size=32, shuffle=True)\n",
    "\n",
    "# 词表大小\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "# 初始化两个学生模型\n",
    "lstm_orig = LSTMStudent(vocab_size)\n",
    "lstm_aug = LSTMStudent(vocab_size)\n",
    "\n",
    "# 优化器\n",
    "optimizer_orig = torch.optim.Adam(lstm_orig.parameters(), lr=2e-4)\n",
    "optimizer_aug = torch.optim.Adam(lstm_aug.parameters(), lr=2e-4)\n",
    "\n",
    "# 训练\n",
    "train_lstm_model(lstm_orig, dataloader_orig, optimizer_orig, device)\n",
    "train_lstm_model(lstm_aug, dataloader_aug, optimizer_aug, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "92debc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_orig.state_dict(), \"lstm_original.pt\")\n",
    "torch.save(lstm_aug.state_dict(), \"lstm_augmented.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5607a619",
   "metadata": {},
   "source": [
    "## 测试并加权融合两个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4c183a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9360\\4220421270.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lstm_orig.load_state_dict(torch.load(\"lstm_original.pt\", map_location=device))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9360\\4220421270.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lstm_aug.load_state_dict(torch.load(\"lstm_augmented.pt\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "Test Accuracy: 0.8390\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ========== 定义模型结构 ==========\n",
    "class LSTMStudent(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, num_classes=2):\n",
    "        super(LSTMStudent, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        embeds = self.embedding(input_ids)\n",
    "        _, (hidden, _) = self.lstm(embeds)\n",
    "        logits = self.classifier(hidden[-1])\n",
    "        return logits\n",
    "\n",
    "# ========== 模型初始化与加载 ==========\n",
    "vocab_size = 30522  # 与训练时一致\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 初始化模型并加载权重\n",
    "lstm_orig = LSTMStudent(vocab_size).to(device)\n",
    "lstm_aug = LSTMStudent(vocab_size).to(device)\n",
    "\n",
    "lstm_orig.load_state_dict(torch.load(\"lstm_original.pt\", map_location=device))\n",
    "lstm_aug.load_state_dict(torch.load(\"lstm_augmented.pt\", map_location=device))\n",
    "\n",
    "lstm_orig.eval()\n",
    "lstm_aug.eval()\n",
    "\n",
    "# ========== 定义预测函数 ==========\n",
    "def predict_lstm(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, _, _, _ in dataloader:\n",
    "            input_ids = input_ids.to(device)\n",
    "            logits = model(input_ids)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            preds.append(probs.cpu())\n",
    "    return torch.cat(preds, dim=0)\n",
    "\n",
    "# ========== 执行预测 ==========\n",
    "# 你需要提前准备好 test_dataset\n",
    "# 例如：test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 预测两个模型输出的概率分布\n",
    "probs_orig = predict_lstm(lstm_orig, test_loader, device)\n",
    "probs_aug = predict_lstm(lstm_aug, test_loader, device)\n",
    "\n",
    "# ========== 加权融合 ==========0.3，0.7\n",
    "final_probs = 0.3* probs_orig + 0.7 * probs_aug\n",
    "final_preds = torch.argmax(final_probs, dim=1)\n",
    "\n",
    "# 输出预测结果\n",
    "print(final_preds)\n",
    "true_labels = torch.tensor([label.item() for _, _, _, label in test_dataset])\n",
    "# 计算准确率\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(true_labels, final_preds)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6af2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
