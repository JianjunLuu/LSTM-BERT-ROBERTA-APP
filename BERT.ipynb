{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "098c9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# 数据读取\n",
    "data = pd.read_csv('./AI_Human.csv')\n",
    "\n",
    "# 数据采样与清洗\n",
    "ai_samples = data[data['generated'] == 1]\n",
    "human_samples = data[data['generated'] == 0]\n",
    "data = pd.concat([ai_samples.sample(n=5000, random_state=42), human_samples.sample(n=5000, random_state=42)])\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 清洗函数\n",
    "def remove_punc(text):\n",
    "    return ''.join([char for char in text if char not in punctuation])\n",
    "\n",
    "def remove_stop(text):\n",
    "    stops = set(stopwords.words('english'))\n",
    "    return \" \".join([word for word in text.split() if word.lower() not in stops])\n",
    "\n",
    "# 文本清洗\n",
    "data['cleaned'] = data['text'].str.lower()\n",
    "data['cleaned'] = data['cleaned'].apply(lambda x: re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', x, flags=re.MULTILINE))\n",
    "data['cleaned'] = data['cleaned'].apply(lambda x: re.sub(r'<.*?>', '', x))\n",
    "data['cleaned'] = data['cleaned'].apply(remove_punc)\n",
    "data['cleaned'] = data['cleaned'].apply(remove_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177919a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dear principal hearing quite lot subject commu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dear state senator writing express opinion ele...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high school students constantly bombarded info...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi im 6th garden think zoos ane nearly cool iv...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sure jars attempt writing essay average 8tj gr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             cleaned  label\n",
       "0  dear principal hearing quite lot subject commu...    0.0\n",
       "1  dear state senator writing express opinion ele...    1.0\n",
       "2  high school students constantly bombarded info...    1.0\n",
       "3  hi im 6th garden think zoos ane nearly cool iv...    1.0\n",
       "4  sure jars attempt writing essay average 8tj gr...    1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['cleaned', 'generated']]\n",
    "data.rename(columns={'generated': 'label'}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3980fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# 数据划分\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['cleaned'].tolist(),\n",
    "    data['label'].tolist(),\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 初始化 BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-base-uncased')\n",
    "max_length = 256\n",
    "batch_size = 16\n",
    "\n",
    "# 自定义 Dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            self.texts[idx],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',  # 填充到 max_length\n",
    "            truncation=True,       # 截断到 max_length\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'    # 返回 PyTorch 张量\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),  # 去掉 batch 维度\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# 批次合并函数\n",
    "def collate_fn(batch):\n",
    "    # 用 pad_sequence 处理 input_ids 和 attention_mask，确保批次内序列对齐\n",
    "    input_ids = pad_sequence([item['input_ids'] for item in batch], batch_first=True, padding_value=0)\n",
    "    attention_mask = pad_sequence([item['attention_mask'] for item in batch], batch_first=True, padding_value=0)\n",
    "    labels = torch.tensor([item['labels'] for item in batch], dtype=torch.long)\n",
    "\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n",
    "\n",
    "\n",
    "# 构建数据集和 DataLoader\n",
    "train_dataset = TextDataset(X_train, y_train, tokenizer, max_length)\n",
    "test_dataset = TextDataset(X_test, y_test, tokenizer, max_length)\n",
    "\n",
    "# 只保留一个 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66310fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 438/438 [45:25<00:00,  6.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.1903910584211962\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 438/438 [44:47<00:00,  6.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.042395465088195965\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████████████████| 438/438 [44:46<00:00,  6.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.023080260041818346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 188/188 [00:57<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9807\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Human-written       0.99      0.97      0.98      1461\n",
      "   AI-written       0.98      0.99      0.98      1539\n",
      "\n",
      "     accuracy                           0.98      3000\n",
      "    macro avg       0.98      0.98      0.98      3000\n",
      " weighted avg       0.98      0.98      0.98      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 初始化 BERT 模型\n",
    "model = BertForSequenceClassification.from_pretrained('./bert-base-uncased', num_labels=2)\n",
    "\n",
    "# 配置优化器和设备\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 训练模型\n",
    "model.train()\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        # outputs 是一个元组，我们需要从中获取损失和 logits\n",
    "        loss = outputs[0]  # 获取第一个元素，即损失\n",
    "        logits = outputs[1]  # 获取第二个元素，即 logits\n",
    "\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "\n",
    "        epoch_loss += loss.item()  # 累加损失\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} Loss: {epoch_loss / len(train_loader)}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87f22610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 188/188 [00:57<00:00,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9807\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Human-written       0.99      0.97      0.98      1461\n",
      "   AI-written       0.98      0.99      0.98      1539\n",
      "\n",
      "     accuracy                           0.98      3000\n",
      "    macro avg       0.98      0.98      0.98      3000\n",
      " weighted avg       0.98      0.98      0.98      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # 测试阶段不需要传入 labels\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs[0]  # 获取 logits\n",
    "\n",
    "        # 预测标签\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 评估模型\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "report = classification_report(true_labels, predictions, target_names=[\"Human-written\", \"AI-written\"])\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4209d6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./saved_model\\\\vocab.txt',\n",
       " './saved_model\\\\special_tokens_map.json',\n",
       " './saved_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存模型\n",
    "model.save_pretrained('./saved_model')\n",
    "\n",
    "# 保存 tokenizer\n",
    "tokenizer.save_pretrained('./saved_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "895244cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "E:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# 加载模型\n",
    "model = BertForSequenceClassification.from_pretrained('./saved_model')\n",
    "\n",
    "# 加载 tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('./saved_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db6e0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "E:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "E:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入文本: The advancements in AI have led to remarkable breakthroughs in various fields.\n",
      "预测结果: AI 生成\n",
      "\n",
      "输入文本: This article discusses the impact of social media on human behavior.\n",
      "预测结果: AI 生成\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "# 设备设置\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# 加载模型和 tokenizer\n",
    "model_path = \"./saved_model\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# 将模型移动到设备并设置为评估模式\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 预处理文本函数\n",
    "def preprocess_text(text, tokenizer, max_length=256):\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"  # 返回 PyTorch 张量\n",
    "    )\n",
    "    return encoding['input_ids'].to(device), encoding['attention_mask'].to(device)\n",
    "\n",
    "# 推理函数\n",
    "def predict(text):\n",
    "    input_ids, attention_mask = preprocess_text(text, tokenizer)\n",
    "    \n",
    "    with torch.no_grad():  # 关闭梯度计算\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        prediction = torch.argmax(logits, dim=1).item()  # 取最大概率的类别\n",
    "        \n",
    "    return \"AI 生成\" if prediction == 1 else \"人类撰写\"\n",
    "\n",
    "# 测试推理\n",
    "if __name__ == \"__main__\":\n",
    "    test_texts = [\n",
    "        \"The advancements in AI have led to remarkable breakthroughs in various fields.\",\n",
    "        \"This article discusses the impact of social media on human behavior.\"\n",
    "    ]\n",
    "\n",
    "    for text in test_texts:\n",
    "        result = predict(text)\n",
    "        print(f\"输入文本: {text}\\n预测结果: {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a715b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
